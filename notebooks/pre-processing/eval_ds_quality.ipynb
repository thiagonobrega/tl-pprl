{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import shutil\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mtick\n",
    "import seaborn as sns\n",
    "\n",
    "import textdistance\n",
    "import missingno as msno\n",
    "\n",
    "from tqdm.notebook import trange, tqdm\n",
    "\n",
    "sys.path.append(\"../libs/\")\n",
    "\n",
    "from datasetutil import open_processed_ds , gerar_gabarito"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metodos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Faltantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "def plotar_dados_faltantes(a,b,dsname,outdir,custom_out=False,custom_id=False):\n",
    "    \n",
    "#     df = pd.concat([a,b])\n",
    "#     df = df.replace(\"nan\", np.nan)\n",
    "#     df = df.replace('', np.nan)\n",
    "#     del df['id']\n",
    "\n",
    "    dfa = a.copy()\n",
    "    dfb = b.copy()\n",
    "    \n",
    "    if not custom_id:\n",
    "        del dfa['id']\n",
    "        del dfb['id']\n",
    "    else:\n",
    "        del dfa[custom_id]\n",
    "        del dfb[custom_id]\n",
    "    \n",
    "#     msno.dendrogram(df,orientation='top')\n",
    "#     msno.dendrogram(df)\n",
    "#     msno.heatmap(df)\n",
    "#     msno.bar(df)\n",
    "    for par in [('a',dfa),('b',dfb)]:\n",
    "        dsid = par[0]\n",
    "        df = par[1]\n",
    "        df = df.replace(\"nan\", np.nan)\n",
    "        df = df.replace('', np.nan)\n",
    "        \n",
    "        plt.ioff()\n",
    "        p = msno.matrix(df,figsize=(10, 6))\n",
    "        p.set_title('Number of unique values per attribute')\n",
    "        fig = p.get_figure()\n",
    "        \n",
    "        if not custom_out:\n",
    "            outf = outdir + dsname + '_' + dsid + '_missing'\n",
    "        else:\n",
    "            outf = outdir + dsname + str(custom_out) + '_' + dsid + '_missing'\n",
    "            \n",
    "        fig.savefig(outf + '.pdf', bbox_inches = 'tight')\n",
    "        fig.savefig(outf + '.png', bbox_inches = 'tight')\n",
    "        plt.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# sdf = msno.nullity_filter(df, filter='bottom', n=15, p=0.999) # or filter='top'\n",
    "# sdf = msno.nullity_filter(df, filter='top', n=15, p=0.999) # or filter='top'\n",
    "\n",
    "# sdf = msno.nullity_sort(df, sort='descending') \n",
    "# sdf = msno.nullity_sort(df, sort='ascending')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Valores Unicos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "def plotar_valores_unicos(a,b,dsname,outdir,\n",
    "                          custom_out=False,custom_id=False):\n",
    "#     df = pd.concat([a,b])\n",
    "#     del df['id']\n",
    "    \n",
    "    dfa = a.copy()\n",
    "    dfb = b.copy()\n",
    "    \n",
    "    if not custom_id:\n",
    "        del dfa['id']\n",
    "        del dfb['id']\n",
    "    else:\n",
    "        del dfa[custom_id]\n",
    "        del dfb[custom_id]\n",
    "    \n",
    "    for par in [('a',dfa),('b',dfb)]:\n",
    "        dsid = par[0]\n",
    "        df = par[1]\n",
    "        df = df.replace(\"nan\", np.nan)\n",
    "        df = df.replace('', np.nan)\n",
    "    \n",
    "        #transformando os dados\n",
    "        sdf = pd.melt(df)\n",
    "        sdf = sdf.loc[sdf['value']!='']\n",
    "        sdf = sdf.loc[sdf['value']!='nan']\n",
    "        # == float(\"NaN\")\n",
    "        z = df.nunique()\n",
    "        tamanho=len(df)\n",
    "        plt.ioff()\n",
    "        fig, ax1 = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "        sns.set_style(\"whitegrid\")\n",
    "\n",
    "        x,y = list(z.index),list(z.values)\n",
    "        # sns.displot(x=x, hue=y, kind=\"kde\", fill=True)\n",
    "        #p = sns.countplot(data=sdf, x='variable', hue='variable')\n",
    "        p = sns.barplot(x=x, y=y, color=(.25,.25,.25))\n",
    "        p.set_title('Number of unique values per attribute')\n",
    "        ax1.set_ylabel('counting')\n",
    "\n",
    "        ax2 = ax1.twinx()\n",
    "        # Ensure ticks occur at the same positions, then modify labels\n",
    "        ax2.set_ylim(ax1.get_ylim())\n",
    "        ax2.set_yticklabels(np.round(ax1.get_yticks()/tamanho,1))\n",
    "        ax2.set_ylabel('Percentage of unique values')\n",
    "\n",
    "        _ = plt.setp(p.get_xticklabels(), rotation=30)\n",
    "\n",
    "        if not custom_out:\n",
    "            outf = outdir + dsname + '_' + dsid + '_unique'\n",
    "        else:\n",
    "            outf = outdir + dsname + str(custom_out) + '_' + dsid + '_unique'\n",
    "\n",
    "        fig.savefig(outf + '.pdf', bbox_inches = 'tight')\n",
    "        fig.savefig(outf + '.png', bbox_inches = 'tight')\n",
    "        plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sim study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "def calcular_similaridade_gabarido(a,b,gold,\n",
    "                                   id_col_a = 'id',id_col_b = 'id'):\n",
    "    cols_a = list(a.columns)\n",
    "    cols_b = list(b.columns)\n",
    "\n",
    "    cols_a.remove(id_col_a)\n",
    "    cols_b.remove(id_col_b)\n",
    "\n",
    "    similaridades = []\n",
    "\n",
    "    for row in gold.iterrows():\n",
    "        id_a = row[1][0]\n",
    "        id_b = row[1][1]\n",
    "\n",
    "        linha1 = a[a[id_col_a]==id_a]\n",
    "        linha2 = b[b[id_col_b]==id_b]\n",
    "\n",
    "        e1 = linha1[cols_a].astype(str).apply(''.join, axis=1)\n",
    "        e1 = e1[e1.keys()[0]]\n",
    "\n",
    "        e2 = linha2[cols_b].astype(str).apply(''.join, axis=1)\n",
    "        e2 = e2[e2.keys()[0]]\n",
    "\n",
    "        h = textdistance.hamming.normalized_similarity(e1,e2)\n",
    "        j = textdistance.jaccard.normalized_similarity(e1,e2)\n",
    "        l = textdistance.levenshtein.normalized_similarity(e1,e2)\n",
    "        e = textdistance.entropy_ncd.normalized_similarity(e1,e2)\n",
    "        o = textdistance.overlap.normalized_similarity(e1,e2)\n",
    "        d = textdistance.sorensen_dice.normalized_similarity(e1,e2)\n",
    "\n",
    "\n",
    "        similaridades.append({'id': str(id_a) +'-'+ str(id_b),\n",
    "                              'hamming' : h,\n",
    "                              'jaccard' : j,\n",
    "    #                           'levenshtein' : l,\n",
    "                              'entropy' : e ,\n",
    "                              'overlap' : o ,\n",
    "                              'sorensen_dice' : d\n",
    "                             })\n",
    "\n",
    "    return pd.DataFrame(similaridades)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "def plotar_similaridade_gabarito(a,b,gold,dsname,outdir,\n",
    "                                 idcola = 'id',idcolb = 'id',\n",
    "                                 custom_out=False):\n",
    "    \n",
    "    plt.ioff()\n",
    "    sdf = calcular_similaridade_gabarido(a,b,gold,id_col_a=idcola, id_col_b=idcolb)\n",
    "    \n",
    "    mdf = sdf.melt(id_vars='id')\n",
    "    mdf.rename(columns = {'id':'id', 'variable': 'metric'}, inplace = True)\n",
    "    \n",
    "    sns.set()\n",
    "    sns.set_style(\"whitegrid\")\n",
    "\n",
    "    fig = plt.figure(figsize=(10, 6))\n",
    "    sns.despine(left=True)\n",
    "    sns.set(style=\"whitegrid\",rc={'figure.figsize':(10,4)})\n",
    "    g = sns.displot(mdf,x='value', hue='metric', element=\"poly\",\n",
    "                    kind=\"hist\",legend=True ,\n",
    "                    height=5, aspect=2)\n",
    "    g.set_xlabels(\"simialarity\")\n",
    "    plt.title(\"Similarity of the duplicated entities\")\n",
    "    \n",
    "    if not custom_out:\n",
    "        outf = outdir + dsname + '_gsim'\n",
    "    else:\n",
    "        outf = outdir + dsname + str(custom_out) + '_gsim'\n",
    "        \n",
    "    plt.savefig(outf + '.pdf', bbox_inches = 'tight')\n",
    "    plt.savefig(outf + '.png', bbox_inches = 'tight')\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Salvar arquivos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "def salvar_mdfile(ds_name,stats,outdir,filename=False,custom_flag=False):\n",
    "    if not filename:\n",
    "        texto = ['# Details of the data source sample', '','' , 'This dataset sample has the folowing characteristics.' , '']\n",
    "    else:\n",
    "        texto = ['# Details of the data source sample ('+filename+')', '','' , 'This dataset sample has the folowing characteristics.' , '']\n",
    "    \n",
    "    texto.append('## Data source sample summary')\n",
    "    texto.append('')\n",
    "#     texto.append(stats.to_markdown(tablefmt=\"grid\"))\n",
    "    texto.append(stats.to_markdown())\n",
    "    texto.append('')\n",
    "    \n",
    "    img1 = '![image](https://github.com/thiagonobrega/ds_utils/blob/master/datasets/'+ds_name+'/stats/'+ds_name+'_missing.png \"Sim\")'\n",
    "    img2 = '![image](https://github.com/thiagonobrega/ds_utils/blob/master/datasets/'+ds_name+'/stats/'+ds_name+'_unique.png \"Sim\")'\n",
    "    img3 = '![image](https://github.com/thiagonobrega/ds_utils/blob/master/datasets/'+ds_name+'/stats/'+ds_name+'_gsim.png \"Sim\")'\n",
    "    \n",
    "    texto.append('## Data source missing values')\n",
    "    texto.append('')\n",
    "    texto.append(img1)\n",
    "    texto.append('')\n",
    "\n",
    "    texto.append('## Data source unique values')\n",
    "    texto.append('')\n",
    "    texto.append(img2)\n",
    "    texto.append('')\n",
    "\n",
    "    texto.append('## Data source duplicated similarities')\n",
    "    texto.append('')\n",
    "    texto.append(img3)\n",
    "    texto.append('')\n",
    "    \n",
    "    if custom_flag:\n",
    "        ff = 'a'\n",
    "    else:\n",
    "        ff = 'w'\n",
    "    with open(outdir+'README.md', ff) as the_file:\n",
    "        for linha in texto:\n",
    "            the_file.write(linha + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "def salvar_textable(ds_name,stats,outdir):   \n",
    "    with open(outdir+ds_name+'.tex', 'w') as the_file:\n",
    "        the_file.write(stats.to_latex() + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Executar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "datasets_dir = \"..\"+os.sep+\"datasets\"+os.sep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "def plotar_sumario(ds_name,ds_file,datasets_dir,custom_out=False,custom_id=False):\n",
    "\n",
    "    ds_dir = ds_name+os.sep\n",
    "    ds_loc = datasets_dir + ds_dir\n",
    "\n",
    "    zdf =  ds_loc + ds_file \n",
    "\n",
    "    a,b,gold,stats = open_processed_ds(zdf,get_stats=True)\n",
    "    \n",
    "    if len(gold.columns) > 2:\n",
    "        gold = gold[gold.iloc[:, 2]==1]\n",
    "    \n",
    "#     if not custom_out:\n",
    "#         print('entrei')\n",
    "#         out_dir = ds_loc + os.sep + 'stats' + os.sep + custom_out\n",
    "#     else:\n",
    "    out_dir = ds_loc + os.sep + 'stats' + os.sep\n",
    "        \n",
    "        \n",
    "    \n",
    "    os.makedirs(out_dir,exist_ok=True)\n",
    "\n",
    "    plotar_dados_faltantes(a,b,ds_name,out_dir,\n",
    "                           custom_out=custom_out,custom_id=custom_id)\n",
    "    plotar_valores_unicos(a,b,ds_name,out_dir,\n",
    "                          custom_out=custom_out,custom_id=custom_id)\n",
    "    \n",
    "    if not custom_id:\n",
    "        plotar_similaridade_gabarito(a,b,gold,ds_name,out_dir,\n",
    "                                     custom_out=custom_out)\n",
    "    else:\n",
    "        plotar_similaridade_gabarito(a,b,gold,ds_name,out_dir,\n",
    "                                     custom_out=custom_out,\n",
    "                                     idcola=custom_id,idcolb=custom_id\n",
    "                                    )        \n",
    "\n",
    "    salvar_mdfile(ds_name,stats,ds_loc,filename=zdf,custom_flag=custom_out)\n",
    "    if not custom_out:\n",
    "        salvar_textable(ds_name,stats,out_dir)\n",
    "    else:\n",
    "        salvar_textable(ds_name+str(custom_out),stats,out_dir)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmdir(dir_path):\n",
    "    try:\n",
    "        shutil.rmtree(dir_path)\n",
    "    except OSError as e:\n",
    "        print(\"Error: %s : %s\" % (dir_path, e.strerror))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## census"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# dsname,arquivo,custom_label,custom_id\n",
    "# custom label when more than one data source in the folter\n",
    "\n",
    "ds = [ \n",
    "        ('census','processed_census.zip',False,False),\n",
    "        ('yv-er','processed_yver.zip',False,False),\n",
    "        ('abt-buy','processed_abt-buy.zip',False,False),\n",
    "        ('books','processed_amazon-barnesnobel.zip','1',False),\n",
    "        ('books','processed_amazon-barnesnobel-small.zip','2',False),\n",
    "        ('books','processed_goodreads-barnesnobel.zip','3',False),\n",
    "        ('dblp-acm','processed_DBLP-ACM.zip',False,False),\n",
    "        ('movies','processed_imdb-rottentomatos.zip','1',False),\n",
    "        ('movies','processed_imdb-tmd.zip','2',False),\n",
    "        ('MVR','michiganvoters_500_0.1.zip',False,False),\n",
    "        ('NCVR','processed_ncvoters_1700_0.1.zip',False,'ncid'),\n",
    "        ('restaurants','processed_fodors-zagats.zip','1',False),\n",
    "        ('restaurants','processed_yelp-yellowpages.zip','2',False),\n",
    "        ('restaurants','processed_yelp-zomato.zip','3',False),\n",
    "        ('tse','processed_tse-2k-8.zip',False,'NR_CPF_CANDIDATO'),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "clean all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for d in ds:\n",
    "    ds_name = d[0]\n",
    "    rmbd = datasets_dir + ds_name + os.sep\n",
    "    rms = rmbd + 'stats'\n",
    "    rmf = rmbd + 'README.md'\n",
    "    rmdir(rms)\n",
    "    try:\n",
    "        os.remove(rmf)\n",
    "    except OSError as e:\n",
    "        print(\"Error: %s : %s\" % (rmf, e.strerror))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "gerar estatticas individuais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for d in tqdm(ds):\n",
    "    ds_file = d[1]\n",
    "    ds_name = d[0]\n",
    "    custom_out = d[2]\n",
    "    custom_id = d[3]\n",
    "    \n",
    "    if not custom_out:\n",
    "        plotar_sumario(ds_name,ds_file,datasets_dir,\n",
    "                       custom_id=custom_id)\n",
    "    else:\n",
    "        plotar_sumario(ds_name,ds_file,datasets_dir,\n",
    "                       custom_out=custom_out,custom_id=custom_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Gerar motivacao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df = []\n",
    "for d in tqdm(ds):\n",
    "    ds_file = d[1]\n",
    "    ds_name = d[0]\n",
    "    custom_out = d[2]\n",
    "    custom_id = d[3]\n",
    "    \n",
    "    ds_dir = ds_name+os.sep\n",
    "    ds_loc = datasets_dir + ds_dir\n",
    "    zdf =  ds_loc + ds_file \n",
    "    a,b,gold,stats = open_processed_ds(zdf,get_stats=True)\n",
    "    \n",
    "    if not custom_id:\n",
    "        ldf = calcular_similaridade_gabarido(a,b,gold)\n",
    "    else:\n",
    "        ldf = calcular_similaridade_gabarido(a,b,gold,\n",
    "                                             id_col_a = custom_id,id_col_b = custom_id)\n",
    "    if not custom_out:\n",
    "        ldf['ds'] = ds_name\n",
    "    else:\n",
    "        ldf['ds'] = ds_name + custom_out\n",
    "    \n",
    "    if len(df) == 0:\n",
    "        df = ldf\n",
    "    else:\n",
    "        df = pd.concat([df,ldf])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "del df['id']\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "mdf = df.copy()\n",
    "mdf['media'] = mdf.iloc[:, :5].astype(float).mean(axis=1)\n",
    "\n",
    "# pessoal= ['census', 'yv-er', 'MVR', 'NCVR' ,'tse']\n",
    "pessoal1 = ['census', 'yv-er' , 'tse' ,'NCVR']\n",
    "set1= ['abt-buy', 'dblp-acm', 'movies2','books3']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def plot_gen1(mdf,desc,log=False):\n",
    "    sns.set()\n",
    "    sns.set_style(\"whitegrid\")\n",
    "    mdf.rename(columns = {'ds': 'data source','media': 'similarity'}, inplace = True)\n",
    "\n",
    "#     = plt.subplot(figsize=(8, 5.5))\n",
    "    fig,ax1 = plt.subplots(figsize=(8,5.5))\n",
    "    sns.despine(left=True)\n",
    "    sns.set(style=\"whitegrid\",rc={'figure.figsize':(10,4)})\n",
    "    g = sns.histplot(mdf,x='similarity', hue='data source', element=\"poly\" #, kind=\"hist\",\n",
    "#                     , stat='density'\n",
    "#                      , stat='probability'\n",
    "                     , stat='count'\n",
    "                     , fill=True ,\n",
    "                    ax=ax1)\n",
    "                    #height=5, aspect=1.5 ,legend=True,)\n",
    "    # g.set_xlabels(\"simialarity\")\n",
    "    if log:\n",
    "        plt.yscale('log')\n",
    "        ax1.get_yaxis().set_major_formatter(mtick.ScalarFormatter())\n",
    "\n",
    "\n",
    "    plt.title(\"Similarity of the duplicated entities\")\n",
    "\n",
    "    outf = datasets_dir +desc+'_original_dss_sim'\n",
    "\n",
    "    plt.savefig(outf + '.pdf', bbox_inches = 'tight')\n",
    "    plt.savefig(outf + '.png', bbox_inches = 'tight')\n",
    "\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plot_gen1(mdf[mdf.ds.isin(pessoal1)],'personal',log=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plot_gen1(mdf[mdf.ds.isin(set1)],'all',log=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "ds_dir = 'abt-buy'+os.sep\n",
    "ds_loc = datasets_dir + ds_dir\n",
    "out_dir = ds_loc + os.sep + 'stats' + os.sep\n",
    "\n",
    "zdf =  ds_loc + 'processed_abt-buy.zip' \n",
    "\n",
    "a,b,gold,stats = open_processed_ds(zdf,get_stats=True)\n",
    "\n",
    "# if len(gold.columns) > 2:\n",
    "#         gold = gold[gold.iloc[:, 2]==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "    import zipfile\n",
    "    get_stats =  True\n",
    "    zf = zipfile.ZipFile(zdf)\n",
    "    nl = zipfile.ZipFile.namelist(zf)\n",
    "\n",
    "    is_one = False\n",
    "    \n",
    "\n",
    "    for i in range(0, len(nl)):\n",
    "\n",
    "        fn = nl[i]\n",
    "\n",
    "        if ('a.csv' == fn):\n",
    "            a = pd.read_csv(zf.open(fn), header=0, sep=\";\",\n",
    "                            index_col=False)\n",
    "            a = a.fillna('')\n",
    "\n",
    "        if ('b.csv' == fn):\n",
    "            b = pd.read_csv(zf.open(fn), header=0, sep=\";\",\n",
    "                            index_col=False)\n",
    "            b = b.fillna('')\n",
    "\n",
    "        if ('gold.csv' in fn):\n",
    "            gs = pd.read_csv(zf.open(fn), header=0, sep=\";\",\n",
    "                             index_col=False)\n",
    "        if get_stats:\n",
    "            if ('stats.csv' in fn):\n",
    "                stats = pd.read_csv(zf.open(fn), header=0, sep=\";\",\n",
    "                                 index_col=False)\n",
    "                is_one = True\n",
    "\n",
    "            if ('stats_a.csv' == fn):\n",
    "                stats_a = pd.read_csv(zf.open(fn) , header=0 , sep=\";\" ,\n",
    "                                 index_col=False)\n",
    "\n",
    "            if ('stats_b.csv' == fn):\n",
    "                stats_b = pd.read_csv(zf.open(fn) , header=0 , sep=\";\" ,\n",
    "                                      index_col=False)\n",
    "\n",
    "\n",
    "    if get_stats:\n",
    "        if not is_one:\n",
    "            stats = pd.concat([stats_a,stats_b])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "calcular_similaridade_gabarido(a,b,gold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "z = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Initialization Cell",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
